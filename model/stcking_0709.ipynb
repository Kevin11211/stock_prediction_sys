{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\student\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\student\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (24.0)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.31-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\student\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (4.66.4)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\student\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\student\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Collecting MarkupSafe>=0.9.2 (from Mako->alembic>=1.5.0->optuna)\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "   ---------------------------------------- 0.0/380.1 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 30.7/380.1 kB 1.3 MB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 41.0/380.1 kB 487.6 kB/s eta 0:00:01\n",
      "   ----------- -------------------------- 112.6/380.1 kB 930.9 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 163.8/380.1 kB 978.3 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 286.7/380.1 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 380.1/380.1 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/233.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 233.0/233.0 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.31-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.1 MB 14.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/2.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.1 MB 7.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 144.7/144.7 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "   ---------------------------------------- 0.0/292.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 292.8/292.8 kB ? eta 0:00:00\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB ? eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Installing collected packages: PyYAML, MarkupSafe, greenlet, colorlog, sqlalchemy, Mako, alembic, optuna\n",
      "Successfully installed Mako-1.3.5 MarkupSafe-2.1.5 PyYAML-6.0.1 alembic-1.13.2 colorlog-6.8.2 greenlet-3.0.3 optuna-3.6.1 sqlalchemy-2.0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: C:\\Users\\student\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: stock_data_all/Finance/0\\AGM.csv\n",
      "Reading file: stock_data_all/Finance/0\\APAM.csv\n",
      "Reading file: stock_data_all/Finance/0\\BANFP.csv\n",
      "Reading file: stock_data_all/Finance/0\\BFZ.csv\n",
      "Reading file: stock_data_all/Finance/0\\BLE.csv\n",
      "Reading file: stock_data_all/Finance/0\\BTCS.csv\n",
      "Reading file: stock_data_all/Finance/0\\BX.csv\n",
      "Reading file: stock_data_all/Finance/0\\BYM.csv\n",
      "Reading file: stock_data_all/Finance/0\\CNS.csv\n",
      "Reading file: stock_data_all/Finance/0\\CXE.csv\n",
      "Reading file: stock_data_all/Finance/0\\EQBK.csv\n",
      "Reading file: stock_data_all/Finance/0\\EVM.csv\n",
      "Reading file: stock_data_all/Finance/0\\EVN.csv\n",
      "Reading file: stock_data_all/Finance/0\\FMY.csv\n",
      "Reading file: stock_data_all/Finance/0\\FNB.csv\n",
      "Reading file: stock_data_all/Finance/0\\FNF.csv\n",
      "Reading file: stock_data_all/Finance/0\\GABC.csv\n",
      "Reading file: stock_data_all/Finance/0\\GECC.csv\n",
      "Reading file: stock_data_all/Finance/0\\GECCO.csv\n",
      "Reading file: stock_data_all/Finance/0\\GJO.csv\n",
      "Reading file: stock_data_all/Finance/0\\GTAC.csv\n",
      "Reading file: stock_data_all/Finance/0\\HTFB.csv\n",
      "Reading file: stock_data_all/Finance/0\\IBCP.csv\n",
      "Reading file: stock_data_all/Finance/0\\MCBS.csv\n",
      "Reading file: stock_data_all/Finance/0\\MCI.csv\n",
      "Reading file: stock_data_all/Finance/0\\MMU.csv\n",
      "Reading file: stock_data_all/Finance/0\\MVF.csv\n",
      "Reading file: stock_data_all/Finance/0\\NEN.csv\n",
      "Reading file: stock_data_all/Finance/0\\NIC.csv\n",
      "Reading file: stock_data_all/Finance/0\\NMI.csv\n",
      "Reading file: stock_data_all/Finance/0\\NMRK.csv\n",
      "Reading file: stock_data_all/Finance/0\\NVG.csv\n",
      "Reading file: stock_data_all/Finance/0\\OFSSH.csv\n",
      "Reading file: stock_data_all/Finance/0\\ONB.csv\n",
      "Reading file: stock_data_all/Finance/0\\OXLCM.csv\n",
      "Reading file: stock_data_all/Finance/0\\OXSQZ.csv\n",
      "Reading file: stock_data_all/Finance/0\\PAI.csv\n",
      "Reading file: stock_data_all/Finance/0\\PCQ.csv\n",
      "Reading file: stock_data_all/Finance/0\\PFSI.csv\n",
      "Reading file: stock_data_all/Finance/0\\PNC.csv\n",
      "Reading file: stock_data_all/Finance/0\\RZC.csv\n",
      "Reading file: stock_data_all/Finance/0\\SAT.csv\n",
      "Reading file: stock_data_all/Finance/0\\SAY.csv\n",
      "Reading file: stock_data_all/Finance/0\\SBI.csv\n",
      "Reading file: stock_data_all/Finance/0\\SFBS.csv\n",
      "Reading file: stock_data_all/Finance/0\\SNV.csv\n",
      "Reading file: stock_data_all/Finance/0\\TCBC.csv\n",
      "Reading file: stock_data_all/Finance/0\\TRINL.csv\n",
      "Reading file: stock_data_all/Finance/0\\UMBF.csv\n",
      "Reading file: stock_data_all/Finance/0\\VFL.csv\n",
      "Reading file: stock_data_all/Finance/0\\ZION.csv\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "directory = \"stock_data_all/Finance/0\"\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        print(f\"Reading file: {filepath}\")\n",
    "        dt = pd.read_csv(filepath)\n",
    "        data.append(dt)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "data = pd.concat(data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(data, pd.DataFrame):\n",
    "    scaler = StandardScaler()\n",
    "    data_ = scaler.fit_transform(data.iloc[:, 1:].values)\n",
    "    ten_day_change = data[\"Close\"].pct_change(periods=10) * 100\n",
    "    data[\"10_day_change_fixed_discrete\"] = pd.cut(\n",
    "        ten_day_change, bins=[-float(\"inf\"), -10, -2, 2, 10, float(\"inf\")], labels=[0, 1, 2, 3, 4]\n",
    "    )\n",
    "else:\n",
    "    print(\"The variable 'data' is not a DataFrame\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: (22770, 60, 71)\n",
      "x_train.shape = (18216, 60, 71)\n",
      "y_train.shape = (18216,)\n",
      "x_test.shape = (4554, 60, 71)\n",
      "y_test.shape = (4554,)\n"
     ]
    }
   ],
   "source": [
    "def split_data(stock, lookback):\n",
    "    data_raw = np.array(stock)\n",
    "    n_time = len(data_raw)\n",
    "    data, targets = [], []\n",
    "    for index in range(0, n_time - lookback, 10):\n",
    "        data.append(data_raw[index : index + lookback, 1:-1])\n",
    "        targets.append(stock[\"10_day_change_fixed_discrete\"].iloc[index + lookback])\n",
    "\n",
    "    data = np.array(data)\n",
    "    targets = np.array(targets)\n",
    "    print(\"Total data:\", data.shape)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data, targets, test_size=0.2, shuffle=True, random_state=42\n",
    "    )\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# Split data\n",
    "lookback = 60\n",
    "x_train, y_train, x_test, y_test = split_data(data, lookback)\n",
    "print(\"x_train.shape =\", x_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"x_test.shape =\", x_test.shape)\n",
    "print(\"y_test.shape =\", y_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "    }\n",
    "    model = RandomForestClassifier(random_state=42, **params)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    return accuracy\n",
    "\n",
    "def xgb_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(random_state=42, **params)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    return accuracy\n",
    "\n",
    "def catboost_objective(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 500),\n",
    "        'depth': trial.suggest_int('depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n",
    "    }\n",
    "    model = CatBoostClassifier(random_state=42, verbose=0, **params)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    return accuracy\n",
    "\n",
    "def mlp_objective(trial):\n",
    "    params = {\n",
    "        'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (100, 50), (200, 100)]),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic']),\n",
    "        'solver': trial.suggest_categorical('solver', ['adam', 'sgd', 'lbfgs']),\n",
    "    }\n",
    "    model = MLPClassifier(random_state=42, **params)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 18:39:52,871] A new study created in memory with name: no-name-0cc618d9-e337-4f04-a99b-07200b13bfac\n",
      "[I 2024-07-09 18:44:13,721] Trial 0 finished with value: 0.7301273605621432 and parameters: {'n_estimators': 370, 'max_depth': 11, 'min_samples_split': 9}. Best is trial 0 with value: 0.7301273605621432.\n",
      "[I 2024-07-09 18:46:31,265] Trial 1 finished with value: 0.7334211682037769 and parameters: {'n_estimators': 163, 'max_depth': 14, 'min_samples_split': 12}. Best is trial 1 with value: 0.7334211682037769.\n",
      "[I 2024-07-09 18:55:10,642] Trial 2 finished with value: 0.7397891963109354 and parameters: {'n_estimators': 484, 'max_depth': 26, 'min_samples_split': 5}. Best is trial 2 with value: 0.7397891963109354.\n",
      "[I 2024-07-09 18:59:23,871] Trial 3 finished with value: 0.7422046552481335 and parameters: {'n_estimators': 254, 'max_depth': 21, 'min_samples_split': 15}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:01:26,071] Trial 4 finished with value: 0.7342995169082126 and parameters: {'n_estimators': 141, 'max_depth': 15, 'min_samples_split': 17}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:02:23,082] Trial 5 finished with value: 0.7263943785682916 and parameters: {'n_estimators': 51, 'max_depth': 26, 'min_samples_split': 6}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:05:40,059] Trial 6 finished with value: 0.741106719367589 and parameters: {'n_estimators': 181, 'max_depth': 30, 'min_samples_split': 20}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:08:12,827] Trial 7 finished with value: 0.7349582784365393 and parameters: {'n_estimators': 154, 'max_depth': 19, 'min_samples_split': 2}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:10:10,644] Trial 8 finished with value: 0.6971892841458058 and parameters: {'n_estimators': 251, 'max_depth': 7, 'min_samples_split': 18}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:12:59,908] Trial 9 finished with value: 0.7389108476064998 and parameters: {'n_estimators': 169, 'max_depth': 21, 'min_samples_split': 8}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:18:44,344] Trial 10 finished with value: 0.7393500219587176 and parameters: {'n_estimators': 344, 'max_depth': 22, 'min_samples_split': 14}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:23:28,063] Trial 11 finished with value: 0.7389108476064998 and parameters: {'n_estimators': 261, 'max_depth': 30, 'min_samples_split': 20}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:29:34,288] Trial 12 finished with value: 0.7375933245498463 and parameters: {'n_estimators': 337, 'max_depth': 30, 'min_samples_split': 15}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:33:27,352] Trial 13 finished with value: 0.7378129117259552 and parameters: {'n_estimators': 224, 'max_depth': 25, 'min_samples_split': 19}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:33:50,919] Trial 14 finished with value: 0.6585419411506368 and parameters: {'n_estimators': 62, 'max_depth': 5, 'min_samples_split': 16}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:40:57,051] Trial 15 finished with value: 0.7417654808959157 and parameters: {'n_estimators': 414, 'max_depth': 23, 'min_samples_split': 13}. Best is trial 3 with value: 0.7422046552481335.\n",
      "[I 2024-07-09 19:47:55,866] Trial 16 finished with value: 0.7362758014931928 and parameters: {'n_estimators': 458, 'max_depth': 17, 'min_samples_split': 12}. Best is trial 3 with value: 0.7422046552481335.\n"
     ]
    }
   ],
   "source": [
    "# Define a callback to stop optimization early if the performance stops improving\n",
    "def early_stopping_callback(study, trial):\n",
    "    if study.best_value - trial.value > 0.01:  # You can adjust the threshold\n",
    "        return True\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(rf_objective, n_trials=100, callbacks=[early_stopping_callback])\n",
    "best_rf = RandomForestClassifier(random_state=42, **study_rf.best_params)\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(xgb_objective, n_trials=100, callbacks=[early_stopping_callback])\n",
    "best_xgb = xgb.XGBClassifier(random_state=42, **study_xgb.best_params)\n",
    "\n",
    "study_catboost = optuna.create_study(direction='maximize')\n",
    "study_catboost.optimize(catboost_objective, n_trials=100, callbacks=[early_stopping_callback])\n",
    "best_catboost = CatBoostClassifier(random_state=42, verbose=0, **study_catboost.best_params)\n",
    "\n",
    "study_mlp = optuna.create_study(direction='maximize')\n",
    "study_mlp.optimize(mlp_objective, n_trials=100, callbacks=[early_stopping_callback])\n",
    "best_mlp = MLPClassifier(random_state=42, **study_mlp.best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models with best parameters from Optuna\n",
    "models = [\n",
    "    (\"RandomForestClassifier\", best_rf),\n",
    "    (\"XGBoostClassifier\", best_xgb),\n",
    "    (\"CatBoostClassifier\", best_catboost),\n",
    "    (\"MLPClassifier\", best_mlp)\n",
    "]\n",
    "\n",
    "# Initialize StackingClassifier\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=models,\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "# Train Stacking model\n",
    "stacking_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_train_pred = stacking_classifier.predict(x_train)\n",
    "y_test_pred = stacking_classifier.predict(x_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(train_cm, annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
    "ax[0].set_title('Train Confusion Matrix')\n",
    "ax[0].set_xlabel('Predicted')\n",
    "ax[0].set_ylabel('Actual')\n",
    "\n",
    "sns.heatmap(test_cm, annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
    "ax[1].set_title('Test Confusion Matrix')\n",
    "ax[1].set_xlabel('Predicted')\n",
    "ax[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
